{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b4b93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 Train Loss: 0.6053 | Val Loss: 0.2486\n",
      "Epoch 2/30 Train Loss: 0.1985 | Val Loss: 0.1865\n",
      "Epoch 3/30 Train Loss: 0.1669 | Val Loss: 0.1653\n",
      "Epoch 4/30 Train Loss: 0.1470 | Val Loss: 0.1488\n",
      "Epoch 5/30 Train Loss: 0.1332 | Val Loss: 0.1331\n",
      "Epoch 6/30 Train Loss: 0.1217 | Val Loss: 0.1235\n",
      "Epoch 7/30 Train Loss: 0.1142 | Val Loss: 0.1166\n",
      "Epoch 8/30 Train Loss: 0.1075 | Val Loss: 0.1087\n",
      "Epoch 9/30 Train Loss: 0.1016 | Val Loss: 0.1038\n",
      "Epoch 10/30 Train Loss: 0.0980 | Val Loss: 0.1008\n",
      "Epoch 11/30 Train Loss: 0.0949 | Val Loss: 0.0974\n",
      "Epoch 12/30 Train Loss: 0.0925 | Val Loss: 0.0946\n",
      "Epoch 13/30 Train Loss: 0.0907 | Val Loss: 0.0931\n",
      "Epoch 14/30 Train Loss: 0.0890 | Val Loss: 0.0918\n",
      "Epoch 15/30 Train Loss: 0.0875 | Val Loss: 0.0902\n",
      "Epoch 16/30 Train Loss: 0.0864 | Val Loss: 0.0890\n",
      "Epoch 17/30 Train Loss: 0.0854 | Val Loss: 0.0878\n",
      "Epoch 18/30 Train Loss: 0.0843 | Val Loss: 0.0869\n",
      "Epoch 19/30 Train Loss: 0.0835 | Val Loss: 0.0858\n",
      "Epoch 20/30 Train Loss: 0.0827 | Val Loss: 0.0852\n",
      "Epoch 21/30 Train Loss: 0.0818 | Val Loss: 0.0845\n",
      "Epoch 22/30 Train Loss: 0.0808 | Val Loss: 0.0828\n",
      "Epoch 23/30 Train Loss: 0.0795 | Val Loss: 0.0820\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ==== ハイパーパラメータ ====\n",
    "SAMPLE_RATE = 16000\n",
    "N_MELS = 64\n",
    "HOP_LENGTH = 512\n",
    "N_FFT = 1024\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# ==== データセット ====\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, folder_path, is_train=True, feature_type=\"log_mel\"):\n",
    "        self.folder_path = folder_path\n",
    "        self.file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".wav\")]\n",
    "        self.is_train = is_train\n",
    "        self.feature_type = feature_type  # \"spectrogram\", \"mel\", \"log_mel\"\n",
    "\n",
    "        if not is_train:\n",
    "            self.labels = [1 if \"anomaly\" in f.split(\"_\")[4] else 0 for f in os.listdir(folder_path)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.file_paths[idx]\n",
    "        y, sr = librosa.load(path, sr=SAMPLE_RATE)\n",
    "\n",
    "        # === 特徴量抽出の切り替え ===\n",
    "        if self.feature_type == \"spectrogram\":\n",
    "            S = np.abs(librosa.stft(y, n_fft=N_FFT, hop_length=HOP_LENGTH)) ** 2\n",
    "            feature = librosa.amplitude_to_db(S, ref=np.max)\n",
    "        elif self.feature_type == \"mel\":\n",
    "            mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=N_FFT,\n",
    "                                                 hop_length=HOP_LENGTH, n_mels=N_MELS)\n",
    "            feature = mel\n",
    "        elif self.feature_type == \"log_mel\":\n",
    "            mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=N_FFT,\n",
    "                                                 hop_length=HOP_LENGTH, n_mels=N_MELS)\n",
    "            feature = librosa.power_to_db(mel, ref=np.max)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid feature_type. Choose from: 'spectrogram', 'mel', 'log_mel'.\")\n",
    "\n",
    "        # 正規化\n",
    "        feature = (feature - feature.mean()) / (feature.std() + 1e-9)\n",
    "        feature_tensor = torch.tensor(feature, dtype=torch.float32).unsqueeze(0)  # (1, F, T)\n",
    "\n",
    "        if self.is_train:\n",
    "            return feature_tensor\n",
    "        else:\n",
    "            label = self.labels[idx]\n",
    "            return feature_tensor, label\n",
    "\n",
    "\n",
    "\n",
    "# ==== Autoencoder モデル ====\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(N_MELS, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, N_MELS, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(1)  # (B, 1, F, T) → (B, F, T)\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x.unsqueeze(1)  # (B, F, T) → (B, 1, F, T)\n",
    "\n",
    "\n",
    "# ==== 学習関数（train/val loss 記録 & 返却）====\n",
    "def train_autoencoder(model, train_loader, val_loader):\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(DEVICE)\n",
    "            output = model(batch)\n",
    "            loss = criterion(output, batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_batch in val_loader:\n",
    "                val_batch = val_batch.to(DEVICE)\n",
    "                val_output = model(val_batch)\n",
    "                val_loss += criterion(val_output, val_batch).item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "\n",
    "# ==== 評価関数（AUC算出）====\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    criterion = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "    scores = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, label in dataloader:\n",
    "            batch = batch.to(DEVICE)\n",
    "            output = model(batch)\n",
    "            loss = criterion(output, batch)\n",
    "            score = loss.mean(dim=(1, 2, 3)).cpu().numpy()\n",
    "            scores.extend(score)\n",
    "            labels.extend(label.numpy())\n",
    "\n",
    "    auc = roc_auc_score(labels, scores)\n",
    "    print(f\"AUC Score: {auc:.4f}\")\n",
    "\n",
    "\n",
    "# ==== グラフ描画 ====\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label=\"Train Loss\")\n",
    "    plt.plot(val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ==== メイン処理 ====\n",
    "if __name__ == \"__main__\":\n",
    "    feature_type = \"log_mel\"  # \"spectrogram\" / \"mel\" / \"log_mel\" をここで切り替える\n",
    "\n",
    "    full_dataset = AudioDataset(\"train\", is_train=True, feature_type=feature_type)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    test_dataset = AudioDataset(\"test\", is_train=False, feature_type=feature_type)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    model = Autoencoder().to(DEVICE)\n",
    "\n",
    "    train_losses, val_losses = train_autoencoder(model, train_loader, val_loader)\n",
    "    plot_losses(train_losses, val_losses)\n",
    "    evaluate(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
